ğŸš€ What This ETL Pipeline Does
1ï¸âƒ£ Extract

Uses Selenium WebDriver to open a webpage

Waits for page elements to load

Scrapes dynamic content

Parses HTML with BeautifulSoup

2ï¸âƒ£ Transform

Stores raw data into a Pandas DataFrame

Cleans missing or invalid values

Normalizes and formats all extracted fields

3ï¸âƒ£ Load

Loads the cleaned dataset into:

SQL Server (pyodbc)

or SQLite (sqlite3)

Automatically creates the table if it doesn't exist